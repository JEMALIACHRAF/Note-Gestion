# Documentation du SystÃ¨me RAG basÃ© sur des Microservices

## Table des MatiÃ¨res
- [1. Introduction](#1-introduction)
- [2. Objectif GÃ©nÃ©ral](#2-objectif-gÃ©nÃ©ral)
- [3. Architecture du SystÃ¨me](#3-architecture-du-systÃ¨me)
  - [3.1 Vue d'ensemble](#31-vue-densemble)
  - [3.2 Architecture Basique RAG](#32-architecture-basique-rag)
- [4. Composants ClÃ©s du Projet](#4-composants-clÃ©s-du-projet)
  - [4.1 Service d'Indexation](#41-service-dindexation)
  - [4.2 Service Agent Conversationnel](#42-service-agent-conversationnel)
  - [4.3 Service MÃ©dia](#43-service-mÃ©dia)
  - [4.4 Composant PartagÃ©](#44-composant-partagÃ©)
  - [4.5 DÃ©ploiement Kubernetes](#45-dÃ©ploiement-kubernetes)
- [5. DÃ©ploiement et Tests](#5-dÃ©ploiement-et-tests)
  - [5.1 DÃ©ploiement avec Docker Hub et Kubernetes](#51-dÃ©ploiement-avec-docker-hub-et-kubernetes)
  - [5.2 VÃ©rification des Services](#52-vÃ©rification-des-services)
  - [5.3 Exposition des Services](#53-exposition-des-services)
- [6. Interaction des Services](#6-interaction-des-services)
  - [6.1 DÃ©tails du Flux dâ€™Interaction](#61-dÃ©tails-du-flux-dinteraction)
- [7. Conclusion](#7-conclusion)

---

## 1. Introduction

Ce document dÃ©crit une plateforme modulaire dâ€™indexation et dâ€™interrogation de donnÃ©es multimodales, intÃ©grant des modÃ¨les dâ€™intelligence artificielle pour la recherche sÃ©mantique et la gÃ©nÃ©ration de rÃ©ponses.

---

## 2. Objectif GÃ©nÃ©ral

Le projet repose sur FastAPI, ChromaDB et LlamaIndex pour traiter, indexer et interroger divers types de donnÃ©es textuelles et audiovisuelles. Il permet une recherche sÃ©mantique efficace et un accÃ¨s structurÃ© aux connaissances.

---

## 3. Architecture du SystÃ¨me

### 3.1 Vue dâ€™Ensemble

Le systÃ¨me repose sur trois microservices principaux et un module partagÃ© :
- **Chat Agent Service** : Fournit un agent conversationnel.
- **Indexing Service** : Service dâ€™indexation de documents.
- **Media Service** : Traitement multimÃ©dia.
- **Composant PartagÃ©** : Gestion des index vectoriels.

### 3.2 Architecture RAG
```plaintext
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Client Utilisateur      â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Chat Agent Service        â”‚
                        â”‚  (chat_agent_service.py)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚           â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”    â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚Indexing Service â”‚    â”‚ Media Service    â”‚
                  â”‚(indexing_serv.) â”‚    â”‚ (media_service)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚           â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Stockage et Index Vector. â”‚
                       â”‚  (vector_index_utils.py)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Composants ClÃ©s du Projet

### 4.1 ğŸ” Service dâ€™Indexation (indexing_service)
- **RÃ´le** : Indexation de fichiers texte (.txt, .md), PDF et autres sources.
- **Moteur** : LlamaIndex pour gÃ©nÃ©rer des embeddings vectoriels.
- **API** :
  - `/indexing/ingest` â†’ Upload et indexation dâ€™un document.
  - `/documents` â†’ Liste des documents indexÃ©s.

### 4.2 ğŸ¤– Service Agent Conversationnel (chat_agent_service)
- **RÃ´le** : RÃ©pond aux requÃªtes utilisateurs via un agent ReAct basÃ© sur GPT-3.5.
- **Moteur** : OpenAI GPT-3.5 + LlamaIndex.
- **API** :
  - `/chat/chat-with-agent` â†’ Envoi dâ€™une requÃªte Ã  lâ€™agent IA.

### 4.3 ğŸ“½ï¸ Service MÃ©dia (media_service)
- **RÃ´le** : Extraction et indexation de contenu multimÃ©dia.
- **API** :
  - `/media/process-and-index` â†’ Traitement dâ€™une vidÃ©o.
  - `/media/process-and-index-image` â†’ Analyse et indexation dâ€™une image.

### 4.4 ğŸ—„ï¸ Composant PartagÃ© (vector_index_utils)
- **RÃ´le** : Gestion centralisÃ©e de lâ€™index vectoriel.
- **Moteur** : LlamaIndex + OpenAI.

### 4.5 ğŸ“¦ DÃ©ploiement Kubernetes
- **Objectif** : Conteneurisation et orchestration des services.
- **Composants** :
  - DÃ©ploiements Kubernetes.
  - Volume partagÃ© pour stocker les fichiers indexÃ©s.

---

## 5. DÃ©ploiement et Tests

### 5.1 DÃ©ploiement avec Docker Hub et Kubernetes
- **Cloner le dÃ©pÃ´t** :
```sh
git clone https://github.com/JEMALIACHRAF/Note-Gestion.git
cd YOUR_REPO/k8s
```
- **Appliquer la configuration du volume** :
```sh
kubectl apply -f shared-volume.yml
```
- **Pull des images Docker** :
```sh
docker pull ashraf081/indexing-service:latest
docker pull ashraf081/media-service:latest
docker pull ashraf081/chat-agent-service:latest
```
- **DÃ©ploiement Kubernetes** :
```sh
kubectl apply -f indexing-service-deployment.yml
kubectl apply -f media-service-deployment.yml
kubectl apply -f chat-agent-service-deployment.yml
```

### 5.2 VÃ©rification des Services
```sh
kubectl get pods
kubectl get services
```

### 5.3 Exposition des Services
```sh
kubectl port-forward svc/indexing-service 8001:8001
kubectl port-forward svc/media-service 8002:8002
kubectl port-forward svc/chat-agent-service 8003:8003
```

---

## 6. Interaction des Services

### 6.1 DÃ©tails du Flux dâ€™Interaction
1. **Indexation** : Documents soumis via `Indexing Service` â†’ Vectorisation.
2. **Traitement MultimÃ©dia** : Extraction et transcription.
3. **RequÃªte Utilisateur** : Analyse et rÃ©cupÃ©ration des documents pertinents.
4. **GÃ©nÃ©ration de RÃ©ponse** : LLM enrichit la rÃ©ponse avec du contexte.

---

## 7. Conclusion

Le projet combine NLP avancÃ©, agents conversationnels et traitement multimÃ©dia pour fournir un moteur de recherche sÃ©mantique puissant, scalable et structurÃ©.

ğŸš€ **Votre application est maintenant prÃªte Ã  Ãªtre utilisÃ©e !** ğŸ‰
